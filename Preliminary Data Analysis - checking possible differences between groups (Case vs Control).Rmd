---
title: "Report of data analysis"
author: "Rodolpho Cortez, Felipe Fagundes"
date: "`r Sys.Date()`"
output: html_notebook
---

```{=html}
<style type="text/css">
.main-container {
  max-width: 85%;
  margin-left: auto;
  margin-right: auto;
}
</style>
```
# **Preliminary Data Analysis - checking possible differences between groups (Case vs Control)**

## **Setting data**

```{r, eval=FALSE}
getwd()
library(readxl)
  data_BPA <- readxl::read_xlsx("./BPAs_EscoreZ.xlsx")
```

Packages `ggplot2`, `ggExtra`, `nortest`, `MKinfer`, `dplyr`, `rstatix`, `Routliers`

```{r, include=FALSE}
#install.packages("Routliers")

library(ggplot2)
library(ggExtra)
library(nortest)
library(MKinfer)
library(dplyr)
library(rstatix)
library(Routliers)
```

# **Checking differences between groups**

The sequence of the analysis encompasses the statistical tests and plots to check normality, and the use of the appropriated statistical tests to check differences. All the Z-Scores were calculated considering the normative data for the most adequated population in the sample. All the means and standard deviations are available in the original datasets of the cognitive tests used.

## **ATTENTION ASSESMENT - BPA measures** {.tabset .tabset-fade}

### **Focused/Concentrated Attention** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}

getwd()

library(readxl)

data_BPA <- readxl::read_xlsx("./BPAs_EscoreZ.xlsx")

glimpse(data_BPA)
data_BPA$GROUP <- as.factor(data_BPA$GROUP)
data_BPA$EDU_LEVEL <- as.factor(data_BPA$EDU_LEVEL)

hist(data_BPA$BPA_CONC_EscoreZ)
summary(data_BPA$BPA_CONC_EscoreZ)
which(data_BPA$BPA_CONC_EscoreZ < -2)

data_BPA <- data_BPA[-c(26),]
```

#### Normality tests

```{r BPA_Conc Normality}

lillie.test(data_BPA$BPA_CONC_EscoreZ)
shapiro.test(data_BPA$BPA_CONC_EscoreZ)

```

```{r, echo=FALSE}

media <- mean(data_BPA$BPA_CONC_EscoreZ)
desvio <- sd(data_BPA$BPA_CONC_EscoreZ)

p <- ggplot(data_BPA, aes(x = BPA_CONC_EscoreZ)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "BPA_CONC_EscoreZ", 
       y = "Density", 
       title = "BPA Conc Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Bootstraped T-Test / Visualizing Frequencies in each group

```{r BPA_Conc T-test - Bootstraped, echo=FALSE}
boot.t.test(BPA_CONC_EscoreZ ~ GROUP, data_BPA)

par(mfrow=c(1,2))
hist(data_BPA$BPA_CONC_EscoreZ [data_BPA$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_BPA$BPA_CONC_EscoreZ [data_BPA$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Split Attention** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}

glimpse(data_BPA)
data_BPA$GROUP <- as.factor(data_BPA$GROUP)
data_BPA$EDU_LEVEL <- as.factor(data_BPA$EDU_LEVEL)

hist(data_BPA$BPA_DIVID_EscoreZ)
summary(data_BPA$BPA_DIVID_EscoreZ)
which(data_BPA$BPA_DIVID_EscoreZ < -2)
```

#### Normality tests

```{r BPA_Divid Normality}
lillie.test(data_BPA$BPA_DIVID_EscoreZ)
shapiro.test(data_BPA$BPA_DIVID_EscoreZ)
```

```{r BPA_Divid Histogram, echo=FALSE}
p <- ggplot(data_BPA, aes(x = BPA_DIVID_EscoreZ)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "BPA_DIVID_EscoreZ", 
       y = "Density", 
       title = "BPA DIVID Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Bootstraped T-Test / Visualizing Frequencies in each group

```{r BPA_Divid T-test, echo=FALSE}
boot.t.test(BPA_DIVID_EscoreZ ~ GROUP, data_BPA)
par(mfrow=c(1,2))
hist(data_BPA$BPA_DIVID_EscoreZ [data_BPA$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_BPA$BPA_DIVID_EscoreZ [data_BPA$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Alternate Attention** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}

glimpse(data_BPA)
data_BPA$GROUP <- as.factor(data_BPA$GROUP)
data_BPA$EDU_LEVEL <- as.factor(data_BPA$EDU_LEVEL)

hist(data_BPA$BPA_ALTERN_EscoreZ)
summary(data_BPA$BPA_ALTERN_EscoreZ)
which(data_BPA$BPA_ALTERN_EscoreZ < -2)
```

#### Normality tests

```{r BPA_Altern Normality, echo=FALSE}
lillie.test(data_BPA$BPA_ALTERN_EscoreZ)
shapiro.test(data_BPA$BPA_ALTERN_EscoreZ)
```

```{r, echo=FALSE}
media <- mean(data_BPA$BPA_ALTERN_EscoreZ)
desvio <- sd(data_BPA$BPA_ALTERN_EscoreZ)

p <- ggplot(data_BPA, aes(x = BPA_ALTERN_EscoreZ)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "BPA_ALTERN_EscoreZ", 
       y = "Density", 
       title = "BPA ALTERN Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r BPA_Altern Wilcoxon Test, echo=FALSE}
wilcox.test(BPA_ALTERN_EscoreZ ~ GROUP, data_BPA, conf.int = TRUE)

data_BPA %>% group_by(GROUP) %>%
  get_summary_stats(BPA_ALTERN_EscoreZ, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_BPA$BPA_ALTERN_EscoreZ [data_BPA$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_BPA$BPA_ALTERN_EscoreZ [data_BPA$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

## **EXECUTIVE FUNCTION ASSESMENT - FDT measures** {.tabset .tabset-fade}

```{r}
data_FDT <- readxl::read_xlsx("./FDT_EscoreZ.xlsx")
```

### **Reading Time** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}


glimpse(data_FDT)
data_FDT$GROUP <- as.factor(data_FDT$GROUP)
data_FDT$EDU_LEVEL <- as.factor(data_FDT$EDU_LEVEL)

hist(data_FDT$FDT_READING_TIME_Z)
summary(data_FDT$FDT_READING_TIME_Z)
which(data_FDT$FDT_READING_TIME_Z < -2)
which(data_FDT$FDT_READING_TIME_Z > 2)

data_FDT <- data_FDT[-c(2 ,  5 , 23 , 25 , 70 , 99 ,102, 104, 114, 120), ]
```

#### Normality Tests

```{r FDT Reading Normality, echo=FALSE}
lillie.test(data_FDT$FDT_READING_TIME_Z)
shapiro.test(data_FDT$FDT_READING_TIME_Z)

media <- mean(data_FDT$FDT_READING_TIME_Z)
desvio <- sd(data_FDT$FDT_READING_TIME_Z)

p <- ggplot(data_FDT, aes(x = FDT_READING_TIME_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "FDT_READING_TIME_Z", 
       y = "Density", 
       title = "FDT Reading Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r FDT Reading Wilcoxon Test, echo=FALSE}
wilcox.test(FDT_READING_TIME_Z ~ GROUP, data_FDT, conf.int = TRUE)

data_FDT %>% group_by(GROUP) %>%
  get_summary_stats(FDT_READING_TIME_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_FDT$FDT_READING_TIME_Z [data_FDT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_FDT$FDT_READING_TIME_Z [data_FDT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```
#### Bootstraped T-Test / Visualizing Frequencies in each group

```{r FDT_READING_TIME_Z T-test, echo=FALSE}
boot.t.test(FDT_READING_TIME_Z ~ GROUP, data_FDT)
par(mfrow=c(1,2))
hist(data_FDT$FDT_READING_TIME_Z [data_FDT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_FDT$FDT_READING_TIME_Z [data_FDT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")

mean(data_FDT$FDT_READING_TIME [data_FDT$GROUP == "CASE"])
mean(data_FDT$FDT_READING_TIME [data_FDT$GROUP == "CONTROL"])
```


### **Counting Time** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_FDT <- readxl::read_xlsx("./FDT_EscoreZ.xlsx")

glimpse(data_FDT)
data_FDT$GROUP <- as.factor(data_FDT$GROUP)
data_FDT$EDU_LEVEL <- as.factor(data_FDT$EDU_LEVEL)

hist(data_FDT$FDT_COUNTING_TIME_Z)
summary(data_FDT$FDT_COUNTING_TIME_Z)
which(data_FDT$FDT_COUNTING_TIME_Z < -2)
which(data_FDT$FDT_COUNTING_TIME_Z > 2)

data_FDT <- data_FDT[-c(14, 24, 25, 70, 116,120), ]
```

#### Normality Tests

```{r FDT Counting Normality, echo=FALSE}
lillie.test(data_FDT$FDT_COUNTING_TIME_Z)
shapiro.test(data_FDT$FDT_COUNTING_TIME_Z)

media <- mean(data_FDT$FDT_COUNTING_TIME_Z)
desvio <- sd(data_FDT$FDT_COUNTING_TIME_Z)

p <- ggplot(data_FDT, aes(x = FDT_COUNTING_TIME_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "FDT_COUNTING_TIME_Z", 
       y = "Density", 
       title = "FDT Counting Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r FDT Counting Wilcoxon Test, echo=FALSE}
wilcox.test(FDT_COUNTING_TIME_Z ~ GROUP, data_FDT, conf.int = TRUE)

data_FDT %>% group_by(GROUP) %>%
  get_summary_stats(FDT_COUNTING_TIME_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_FDT$FDT_COUNTING_TIME_Z [data_FDT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_FDT$FDT_COUNTING_TIME_Z [data_FDT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Choosing Time** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_FDT <- readxl::read_xlsx("./FDT_EscoreZ.xlsx")

glimpse(data_FDT)
data_FDT$GROUP <- as.factor(data_FDT$GROUP)
data_FDT$EDU_LEVEL <- as.factor(data_FDT$EDU_LEVEL)

hist(data_FDT$FDT_CHOOSING_TIME_Z)
summary(data_FDT$FDT_CHOOSING_TIME_Z)
which(data_FDT$FDT_CHOOSING_TIME_Z < -2)
which(data_FDT$FDT_CHOOSING_TIME_Z > 2)

data_FDT <- data_FDT[-c(12,  20,  23,  24,  25,  28,  70, 116), ]
```

#### Normality Tests

```{r FDT Choosing Normality, echo=FALSE}
lillie.test(data_FDT$FDT_CHOOSING_TIME_Z)
shapiro.test(data_FDT$FDT_CHOOSING_TIME_Z)

media <- mean(data_FDT$FDT_CHOOSING_TIME_Z)
desvio <- sd(data_FDT$FDT_CHOOSING_TIME_Z)

p <- ggplot(data_FDT, aes(x = FDT_CHOOSING_TIME_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "FDT_CHOOSING_TIME_Z", 
       y = "Density", 
       title = "FDT Choosing Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r FDT Choosing Wilcoxon Test, echo=FALSE}
wilcox.test(FDT_CHOOSING_TIME_Z ~ GROUP, data_FDT, conf.int = TRUE)


data_FDT %>% group_by(GROUP) %>%
  get_summary_stats(FDT_CHOOSING_TIME_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_FDT$FDT_CHOOSING_TIME_Z [data_FDT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_FDT$FDT_CHOOSING_TIME_Z [data_FDT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Changing Time** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_FDT <- readxl::read_xlsx("./FDT_EscoreZ.xlsx")

glimpse(data_FDT)
data_FDT$GROUP <- as.factor(data_FDT$GROUP)
data_FDT$EDU_LEVEL <- as.factor(data_FDT$EDU_LEVEL)

hist(data_FDT$FDT_CHANGING_TIME_Z)
summary(data_FDT$FDT_CHANGING_TIME_Z)
which(data_FDT$FDT_CHANGING_TIME_Z < -2)
which(data_FDT$FDT_CHANGING_TIME_Z > 2)


data_FDT <- data_FDT[-c(5, 23, 24, 25, 28, 109, 116), ]
```

#### Normality Tests

```{r FDT Changing Normality, echo=FALSE}
lillie.test(data_FDT$FDT_CHANGING_TIME_Z)
shapiro.test(data_FDT$FDT_CHANGING_TIME_Z)

media <- mean(data_FDT$FDT_CHANGING_TIME_Z)
desvio <- sd(data_FDT$FDT_CHANGING_TIME_Z)

p <- ggplot(data_FDT, aes(x = FDT_CHANGING_TIME_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "FDT_CHOOSING_TIME_Z", 
       y = "Density", 
       title = "FDT Changing Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r FDT Changing Wilcoxon Test, echo=FALSE}
wilcox.test(FDT_CHANGING_TIME_Z ~ GROUP, data_FDT, conf.int = TRUE)

data_FDT %>% group_by(GROUP) %>%
  get_summary_stats(FDT_CHANGING_TIME_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_FDT$FDT_CHANGING_TIME_Z [data_FDT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_FDT$FDT_CHANGING_TIME_Z [data_FDT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Inhibition** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_FDT <- readxl::read_xlsx("./FDT_EscoreZ.xlsx")

glimpse(data_FDT)
data_FDT$GROUP <- as.factor(data_FDT$GROUP)
data_FDT$EDU_LEVEL <- as.factor(data_FDT$EDU_LEVEL)

hist(data_FDT$FDT_INHIBITION_Z)
summary(data_FDT$FDT_INHIBITION_Z)
which(data_FDT$FDT_INHIBITION_Z < -2)
which(data_FDT$FDT_INHIBITION_Z > 2)


data_FDT <- data_FDT[-c(10,  12,  20,  24,  28,  82, 116), ]
```

#### Normality Tests

```{r FDT Inhibition Normality, echo=FALSE}
lillie.test(data_FDT$FDT_INHIBITION_Z)
shapiro.test(data_FDT$FDT_INHIBITION_Z)

media <- mean(data_FDT$FDT_INHIBITION_Z)
desvio <- sd(data_FDT$FDT_INHIBITION_Z)

p <- ggplot(data_FDT, aes(x = FDT_INHIBITION_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "FDT_INHIBITION_Z", 
       y = "Density", 
       title = "FDT Inhibition Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r FDT Inhibition Wilcoxon Test, echo=FALSE}
wilcox.test(FDT_INHIBITION_Z ~ GROUP, data_FDT, conf.int = TRUE)

data_FDT %>% group_by(GROUP) %>%
  get_summary_stats(FDT_INHIBITION_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_FDT$FDT_INHIBITION_Z [data_FDT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_FDT$FDT_INHIBITION_Z [data_FDT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Flexibility** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_FDT <- readxl::read_xlsx("./FDT_EscoreZ.xlsx")

glimpse(data_FDT)
data_FDT$GROUP <- as.factor(data_FDT$GROUP)
data_FDT$EDU_LEVEL <- as.factor(data_FDT$EDU_LEVEL)

hist(data_FDT$FDT_FLEXIBILITY_Z)
summary(data_FDT$FDT_FLEXIBILITY_Z)
which(data_FDT$FDT_FLEXIBILITY_Z < -2)
which(data_FDT$FDT_FLEXIBILITY_Z > 2)

data_FDT <- data_FDT[-c(5, 10,  24,  28,  69, 109, 116), ]
```

#### Normality Tests

```{r FDT Flexibility Normality, echo=FALSE}
lillie.test(data_FDT$FDT_FLEXIBILITY_Z)
shapiro.test(data_FDT$FDT_FLEXIBILITY_Z)

media <- mean(data_FDT$FDT_FLEXIBILITY_Z)
desvio <- sd(data_FDT$FDT_FLEXIBILITY_Z)

p <- ggplot(data_FDT, aes(x = FDT_FLEXIBILITY_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "FDT_FLEXIBILITY_Z", 
       y = "Density", 
       title = "FDT Flexibility Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r FDT Flexibility Wilcoxon Test, echo=FALSE}
wilcox.test(FDT_FLEXIBILITY_Z ~ GROUP, data_FDT, conf.int = TRUE)

data_FDT %>% group_by(GROUP) %>%
  get_summary_stats(FDT_FLEXIBILITY_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_FDT$FDT_FLEXIBILITY_Z [data_FDT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_FDT$FDT_FLEXIBILITY_Z [data_FDT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```
#### Bootstraped T-Test / Visualizing Frequencies in each group

```{r FDT_FLEXIBILITY_Z T-test, echo=FALSE}
boot.t.test(FDT_FLEXIBILITY_Z ~ GROUP, data_FDT)
par(mfrow=c(1,2))
hist(data_FDT$FDT_FLEXIBILITY_Z [data_FDT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_FDT$FDT_FLEXIBILITY_Z [data_FDT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")

mean(data_FDT$FDT_FLEXIBILITY [data_FDT$GROUP == "CASE"])
mean(data_FDT$FDT_FLEXIBILITY [data_FDT$GROUP == "CONTROL"])
```


## **MEMORY ASSESMENT - RAVLT measures** {.tabset .tabset-fade}

```{r}
data_RAVLT <- readxl::read_xlsx("./RAVLTs_EscoreZ.xlsx")
```

### **Short-term memory - First try** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_RAVLT <- readxl::read_xlsx("./RAVLTs_EscoreZ.xlsx")

glimpse(data_RAVLT)
data_RAVLT$GROUP <- as.factor(data_RAVLT$GROUP)
data_RAVLT$EDU_LEVEL <- as.factor(data_RAVLT$EDU_LEVEL)

hist(data_RAVLT$RAVLT_A1_Z)
summary(data_RAVLT$RAVLT_A1_Z)
which(data_RAVLT$RAVLT_A1_Z < -2)
which(data_RAVLT$RAVLT_A1_Z > 2)

data_RAVLT <- data_RAVLT[-c(3, 10, 14, 89), ]
```

#### Normality Tests

```{r RAVLT Short-term A1, echo=FALSE}
lillie.test(data_RAVLT$RAVLT_A1_Z)
shapiro.test(data_RAVLT$RAVLT_A1_Z)

media <- mean(data_RAVLT$RAVLT_A1_Z)
desvio <- sd(data_RAVLT$RAVLT_A1_Z)

p <- ggplot(data_RAVLT, aes(x = RAVLT_A1_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "RAVLT_A1_Z", 
       y = "Density", 
       title = "RAVLT Short-term memory A1 Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```
#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r RAVLT_A1_Z Wilcoxon Test, echo=FALSE}
wilcox.test(RAVLT_A1_Z ~ GROUP, data_RAVLT, conf.int = TRUE)

data_RAVLT %>% group_by(GROUP) %>%
  get_summary_stats(RAVLT_A1_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_RAVLT$RAVLT_A1_Z [data_RAVLT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_RAVLT$RAVLT_A1_Z [data_RAVLT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

#### Bootstraped T-Test / Visualizing Frequencies in each group

```{r RAVLT Short-term A1 T-test - Bootstraped, echo=FALSE}
boot.t.test(RAVLT_A1_Z ~ GROUP, data_RAVLT)

par(mfrow=c(1,2))
hist(data_RAVLT$RAVLT_A1_Z [data_RAVLT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_RAVLT$RAVLT_A1_Z [data_RAVLT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Short-term memory - Fifth try** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_RAVLT <- readxl::read_xlsx("./RAVLTs_EscoreZ.xlsx")

glimpse(data_RAVLT)
data_RAVLT$GROUP <- as.factor(data_RAVLT$GROUP)
data_RAVLT$EDU_LEVEL <- as.factor(data_RAVLT$EDU_LEVEL)

hist(data_RAVLT$RAVLT_A5_Z)
summary(data_RAVLT$RAVLT_A5_Z)
which(data_RAVLT$RAVLT_A5_Z < -2)
which(data_RAVLT$RAVLT_A5_Z > 2)

data_RAVLT <- data_RAVLT[-c(10, 12, 63, 84, 102, 103), ]
```

#### Normality Tests

```{r RAVLT Short-term A5, echo=FALSE}
lillie.test(data_RAVLT$RAVLT_A5_Z)
shapiro.test(data_RAVLT$RAVLT_A5_Z)

media <- mean(data_RAVLT$RAVLT_A5_Z)
desvio <- sd(data_RAVLT$RAVLT_A5_Z)

p <- ggplot(data_RAVLT, aes(x = RAVLT_A5_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "RAVLT_A5_Z", 
       y = "Density", 
       title = "RAVLT Short-term memory A5 Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r RAVLT Short-term A5 Wilcoxon Test, echo=FALSE}
wilcox.test(RAVLT_A5_Z ~ GROUP, data_RAVLT, conf.int = TRUE)

data_RAVLT %>% group_by(GROUP) %>%
  get_summary_stats(RAVLT_A5_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_RAVLT$RAVLT_A5_Z [data_RAVLT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_RAVLT$RAVLT_A5_Z [data_RAVLT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Long-term memory - Evocation** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_RAVLT <- readxl::read_xlsx("./RAVLTs_EscoreZ.xlsx")

glimpse(data_RAVLT)
data_RAVLT$GROUP <- as.factor(data_RAVLT$GROUP)
data_RAVLT$EDU_LEVEL <- as.factor(data_RAVLT$EDU_LEVEL)

hist(data_RAVLT$RAVLT_A7_Z)
summary(data_RAVLT$RAVLT_A7_Z)
which(data_RAVLT$RAVLT_A7_Z < -2)
which(data_RAVLT$RAVLT_A7_Z > 2)

data_RAVLT <- data_RAVLT[-c(3, 12, 23, 29, 57, 71, 73, 84), ]
```

#### Normality Tests

```{r RAVLT Long-term Evocation, echo=FALSE}
lillie.test(data_RAVLT$RAVLT_A7_Z)
shapiro.test(data_RAVLT$RAVLT_A7_Z)

media <- mean(data_RAVLT$RAVLT_A7_Z)
desvio <- sd(data_RAVLT$RAVLT_A7_Z)

p <- ggplot(data_RAVLT, aes(x = RAVLT_A7_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "RAVLT_A7_Z", 
       y = "Density", 
       title = "RAVLT Short-term memory A7 Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Bootstraped T-Test / Visualizing Frequencies in each group

```{r RAVLT Long-term RAVLT_A7_Z T-test - Bootstraped, echo=FALSE}
boot.t.test(RAVLT_A7_Z ~ GROUP, data_RAVLT)

par(mfrow=c(1,2))
hist(data_RAVLT$RAVLT_A7_Z [data_RAVLT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_RAVLT$RAVLT_A7_Z [data_RAVLT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Long-term memory - Recognition** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_RAVLT <- readxl::read_xlsx("./RAVLTs_EscoreZ.xlsx")


glimpse(data_RAVLT)
data_RAVLT$GROUP <- as.factor(data_RAVLT$GROUP)
data_RAVLT$EDU_LEVEL <- as.factor(data_RAVLT$EDU_LEVEL)

hist(data_RAVLT$RAVLT_REC_Z)
summary(data_RAVLT$RAVLT_REC_Z)
which(data_RAVLT$RAVLT_REC_Z < -2)
which(data_RAVLT$RAVLT_REC_Z > 2)

data_RAVLT <- data_RAVLT[-c(105), ]
```

#### Normality Tests

```{r RAVLT Long-term Recognition, echo=FALSE}
lillie.test(data_RAVLT$RAVLT_REC_Z)
shapiro.test(data_RAVLT$RAVLT_REC_Z)

media <- mean(data_RAVLT$RAVLT_REC_Z)
desvio <- sd(data_RAVLT$RAVLT_REC_Z)

p <- ggplot(data_RAVLT, aes(x = RAVLT_REC_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "RAVLT_Rec_Z", 
       y = "Density", 
       title = "RAVLT Long-term memory Rec Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r RAVLT Long-term Recognition Wilcoxon Test, echo=FALSE}
wilcox.test(RAVLT_REC_Z ~ GROUP, data_RAVLT, conf.int = TRUE)

data_RAVLT %>% group_by(GROUP) %>%
  get_summary_stats(RAVLT_REC_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_RAVLT$RAVLT_REC_Z [data_RAVLT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_RAVLT$RAVLT_REC_Z [data_RAVLT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```

### **Retention - From the last of short-term to the evocation** {.tabset .tabset-fade}

#### Setting and cleaning data
```{r, eval=FALSE}
data_RAVLT <- readxl::read_xlsx("./RAVLTs_EscoreZ.xlsx")

data_RAVLT <- data_RAVLT %>% filter(RAVLT_RETENTION_Z < 5)


glimpse(data_RAVLT)
data_RAVLT$GROUP <- as.factor(data_RAVLT$GROUP)
data_RAVLT$EDU_LEVEL <- as.factor(data_RAVLT$EDU_LEVEL)

hist(data_RAVLT$RAVLT_RETENTION_Z)
summary(data_RAVLT$RAVLT_RETENTION_Z)
which(data_RAVLT$RAVLT_RETENTION_Z < -2)
which(data_RAVLT$RAVLT_RETENTION_Z > 2)

data_RAVLT <- data_RAVLT[-c(23, 106, 117), ]
```

#### Normality Tests

```{r RAVLT Retention, echo=FALSE}
lillie.test(data_RAVLT$RAVLT_RETENTION_Z)
shapiro.test(data_RAVLT$RAVLT_RETENTION_Z)

media <- mean(data_RAVLT$RAVLT_RETENTION_Z)
desvio <- sd(data_RAVLT$RAVLT_RETENTION_Z)

p <- ggplot(data_RAVLT, aes(x = RAVLT_RETENTION_Z)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = media, sd = desvio), color = "tomato", size = 1.5) +
  
  labs(x = "RAVLT_Retention_Z", 
       y = "Density", 
       title = "RAVLT RETENTION Z-escore, Gaussian Density Curve") +
  theme_minimal()
p
```

#### Mann-Whitney (Wilcoxon rank-sum test) / Visualizing Frequencies in each group

```{r RAVLT Retention Wilcoxon Test, echo=FALSE}
wilcox.test(RAVLT_RETENTION_Z ~ GROUP, data_RAVLT, conf.int = TRUE)

data_RAVLT %>% group_by(GROUP) %>%
  get_summary_stats(RAVLT_RETENTION_Z, type = "median_iqr")

par(mfrow=c(1,2))
hist(data_RAVLT$RAVLT_RETENTION_Z [data_RAVLT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_RAVLT$RAVLT_RETENTION_Z [data_RAVLT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```
#### Bootstraped T-Test / Visualizing Frequencies in each group

```{r RAVLT Long-term Retention T-test - Bootstraped, echo=FALSE}
boot.t.test(RAVLT_RETENTION_Z ~ GROUP, data_RAVLT)

par(mfrow=c(1,2))
hist(data_RAVLT$RAVLT_RETENTION_Z [data_RAVLT$GROUP == "CASE"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CASE")
hist(data_RAVLT$RAVLT_RETENTION_Z [data_RAVLT$GROUP == "CONTROL"], xlim = c(-5, 5),
     ylab = "Frequency", xlab = "Z Score", main = "Group - CONTROL")
```